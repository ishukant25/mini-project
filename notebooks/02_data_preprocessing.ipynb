{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a739a0d7-f0ba-46e8-8628-8e73eb6fcf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the cleaned dataset:\n",
      "         id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302        17.99         10.38          122.80     1001.0   \n",
      "1    842517        20.57         17.77          132.90     1326.0   \n",
      "2  84300903        19.69         21.25          130.00     1203.0   \n",
      "3  84348301        11.42         20.38           77.58      386.1   \n",
      "4  84358402        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "0         0.2419  ...          17.33           184.60      2019.0   \n",
      "1         0.1812  ...          23.41           158.80      1956.0   \n",
      "2         0.2069  ...          25.53           152.50      1709.0   \n",
      "3         0.2597  ...          26.50            98.87       567.7   \n",
      "4         0.1809  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  diagnosis_encoded  \n",
      "0          0.4601                  0.11890                  1  \n",
      "1          0.2750                  0.08902                  1  \n",
      "2          0.3613                  0.08758                  1  \n",
      "3          0.6638                  0.17300                  1  \n",
      "4          0.2364                  0.07678                  1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "First 5 rows after dropping the `id` column:\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  diagnosis_encoded  \n",
      "0          0.4601                  0.11890                  1  \n",
      "1          0.2750                  0.08902                  1  \n",
      "2          0.3613                  0.08758                  1  \n",
      "3          0.6638                  0.17300                  1  \n",
      "4          0.2364                  0.07678                  1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Shape of features (X): (569, 30)\n",
      "Shape of target (y): (569,)\n",
      "\n",
      "Shape of training set (X_train): (455, 30)\n",
      "Shape of testing set (X_test): (114, 30)\n",
      "Shape of training labels (y_train): (455,)\n",
      "Shape of testing labels (y_test): (114,)\n",
      "\n",
      "First 5 rows of the normalized training set:\n",
      "[[-1.44075296 -0.43531947 -1.36208497 -1.1391179   0.78057331  0.71892128\n",
      "   2.82313451 -0.11914956  1.09266219  2.45817261 -0.26380039 -0.01605246\n",
      "  -0.47041357 -0.47476088  0.83836493  3.25102691  8.43893667  3.39198733\n",
      "   2.62116574  2.06120787 -1.23286131 -0.47630949 -1.24792009 -0.97396758\n",
      "   0.72289445  1.18673232  4.67282796  0.9320124   2.09724217  1.88645014]\n",
      " [ 1.97409619  1.73302577  2.09167167  1.85197292  1.319843    3.42627493\n",
      "   2.01311199  2.66503199  2.1270036   1.55839569  0.80531919 -0.81268678\n",
      "   0.75195659  0.87716951 -0.89605315  1.18122247  0.18362761  0.60059598\n",
      "  -0.31771686  0.52963649  2.17331385  1.3112795   2.08161691  2.1374055\n",
      "   0.76192793  3.26560084  1.92862053  2.6989469   1.89116053  2.49783848]\n",
      " [-1.39998202 -1.24962228 -1.34520926 -1.10978518 -1.33264483 -0.30735463\n",
      "  -0.36555756 -0.69650228  1.93033305  0.95437877  0.02752055  1.96305996\n",
      "  -0.12095781 -0.35077918  0.57276579  0.7394992   0.32065553  0.58946222\n",
      "   2.61504052  0.71892779 -1.29528358 -1.04081128 -1.24522047 -0.99971493\n",
      "  -1.43869328 -0.54856427 -0.64491059 -0.97023893  0.59760192  0.0578942 ]\n",
      " [-0.98179678  1.41622208 -0.98258746 -0.86694414  0.05938999 -0.59678772\n",
      "  -0.82020317 -0.84511471  0.31326409  0.07404147 -0.53850473  0.53647286\n",
      "  -0.65795    -0.49659014  0.0654747  -0.82240418 -0.68556537 -0.89848456\n",
      "   0.12329928 -0.43154667 -0.8291973   1.59353039 -0.87357215 -0.74294685\n",
      "   0.79662437 -0.7293916  -0.77494969 -0.80948314  0.79892783 -0.1344968 ]\n",
      " [-1.11769991 -1.0102595  -1.12500192 -0.96594206  1.26951116 -0.43900185\n",
      "  -0.98334145 -0.93059974  3.39443604  0.95021314  0.40227808  0.4403815\n",
      "   0.21931447 -0.11553185  0.17191085 -0.78797021 -0.78350919 -0.58864808\n",
      "   2.60401511  0.76598123 -1.08512861 -1.3346163  -1.11713828 -0.89654919\n",
      "  -0.17487574 -0.99507862 -1.20914641 -1.35458167  1.03354385 -0.20573196]]\n",
      "\n",
      "Distribution of the target variable in the training set:\n",
      "diagnosis_encoded\n",
      "0    286\n",
      "1    169\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of the target variable after SMOTE:\n",
      "diagnosis_encoded\n",
      "0    286\n",
      "1    286\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data preprocessing completed! Preprocessed data saved to `data/processed/`.\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.14.4\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# # Breast Cancer Prediction - Data Preprocessing\n",
    "\n",
    "# ## 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ## 2. Load the Cleaned Dataset\n",
    "# Load the cleaned dataset from the `data/processed/` folder\n",
    "df = pd.read_csv('../data/processed/breast_cancer_clean.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the cleaned dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# ## 3. Drop Unnecessary Columns\n",
    "# Drop the `id` column as it is not useful for prediction\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "# Display the first few rows after dropping the `id` column\n",
    "print(\"\\nFirst 5 rows after dropping the `id` column:\")\n",
    "print(df.head())\n",
    "\n",
    "# ## 4. Split the Data into Features and Target\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('diagnosis_encoded', axis=1)\n",
    "y = df['diagnosis_encoded']\n",
    "\n",
    "# Display the shape of features and target\n",
    "print(\"\\nShape of features (X):\", X.shape)\n",
    "print(\"Shape of target (y):\", y.shape)\n",
    "\n",
    "# ## 5. Split the Data into Training and Testing Sets\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of training and testing sets\n",
    "print(\"\\nShape of training set (X_train):\", X_train.shape)\n",
    "print(\"Shape of testing set (X_test):\", X_test.shape)\n",
    "print(\"Shape of training labels (y_train):\", y_train.shape)\n",
    "print(\"Shape of testing labels (y_test):\", y_test.shape)\n",
    "\n",
    "# ## 6. Normalize Numerical Features\n",
    "# Normalize the numerical features to ensure all features are on the same scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Display the first few rows of the normalized training set\n",
    "print(\"\\nFirst 5 rows of the normalized training set:\")\n",
    "print(X_train[:5])\n",
    "\n",
    "# ## 7. Handle Class Imbalance (if any)\n",
    "# Check the distribution of the target variable in the training set\n",
    "print(\"\\nDistribution of the target variable in the training set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Apply SMOTE to balance the classes (if imbalanced)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display the distribution of the target variable after SMOTE\n",
    "print(\"\\nDistribution of the target variable after SMOTE:\")\n",
    "print(pd.Series(y_res).value_counts())\n",
    "\n",
    "# ## 8. Save the Preprocessed Data\n",
    "# Save the preprocessed data to the `data/processed/` folder\n",
    "np.save('../data/processed/X_train.npy', X_res)\n",
    "np.save('../data/processed/X_test.npy', X_test)\n",
    "np.save('../data/processed/y_train.npy', y_res)\n",
    "np.save('../data/processed/y_test.npy', y_test)\n",
    "\n",
    "print(\"\\nData preprocessing completed! Preprocessed data saved to `data/processed/`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e2447-985d-4d0b-a59b-345bc68eeab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
